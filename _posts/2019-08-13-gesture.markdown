---
title: "\U0001F44B Exploring hand gestural control for mobile devices"
layout: post
date: 2019-08-11 22:00
tag:
- Cross-device
- Data Visualisation
- Statistical test
- Exit Interview
- Questionnaires
- Mixed-method
projects: true
category: project
author: chloeng
description: Gesture Elicitation
---

## Eliciting User-defined Touch and Mid-air Gestures for Co-located Mobile Gaming
<b>
<b>Project area: </b> Gesture elicitation, Interview, Survey, Think-aloud

<b>
<b>Type: </b> Individual project

<b>
<b>My role: </b> I managed the entire project starting from literature review of past gesture elicitation studies and gestural control. Following the study design, which includes survey design, artifact design, interview script, I went on recruiting participants and carrying out the lab sessions. After collecting video recordings of the elicitation and survey response, I coded the quant/qual data for analysis, subsequently writing up the report.

<b>
<b>Methods: </b> questionnaires, interviews, thematic analysis, data visualisation, descriptive statistics, t-tests

<b>
<b>Time: </b> 6 months

#### Background
<b>
In recent years, mobile games have become increasingly popular and have largely improved on their interaction techniques. This improvement is enabled by the increasing capability in modern mobile devices as they feature sophisticated sensors such as accelerometers, gyroscope, and motion sensors, which allows for a vast range of input methods. 

<b>
To make use of the improving capability in mobile devices in the domain of mobile games, there has been research that explores alternative input methods (other than using capacitive touchscreens).

<b>
In this research, I aim <span class="evidence">to explore the use of gesture controls in co-located mobile gaming, an area that has not been focused on in the industry and research community</span>. I will explore traditional multiplayer tabletop games such as board and card games due to their clearly defined game tasks, and the communicative nature of the game, and the materiality of the game materials cherished by players in a co-located setting.

<img alt="example gestures" src="https://chloenhy.github.io/assets/images/gesture/example-gesture.jpg" />

#### Research Approach
<b>
I draw upon the widely adopted gesture elicitation methodology to understand user mental models and help develop user-defined gestures. User elicitation is one form of participatory design to include users’ mental models and proposals in designing new interaction techniques. Elicitation studies aim to invoke easy-to-learn and memorable user-defined gestures instead of gestures that are optimised for machine recognition. In an elicitation, participants are asked to propose gestures to achieve tasks (known as referents) in a specified modality.

<b>
I conducted a gesture elicitation study for tasks common in a multiplayer card and board game moderated by mobile devices. I recruited 24 participants in pairs. Twelve were working professionals different backgrounds such as analytics, marketing, engineering, clinical settings, and sports. The other twelve were university students in various disciplines.

<img alt="participants" src="https://chloenhy.github.io/assets/images/gesture/participants.jpg" align="middle"/>

We seek answers to our research question: 

<b>How can the results and observations made in a gesture elicitation for game tasks inform gesture design in co-located multiplayer mobile games?</b>




#### Data Collection and Analysis
Data collected include observational notes jotted by the experimenter and the video recordings of the entire sessions, including the elicitation and the post-study interviews. The pre- and post-study questionnaires contain demographic, technology usage habits, Likert-scale and free-form responses. Descriptive statistics were generated from the Likert-scale questions. 

All gestures were coded (and fed into the AGAte 2.0 tool for agreement rate calculation.
<br>
<br>
<img alt="example gestures" src="https://chloenhy.github.io/assets/images/gesture/agate.jpg" align="middle"/>


#### Results
##### Quantitative 
A total of 662 gesture proposals, with 286 distinct gestures (by referents) were collected. t-tests were performed to compare gesture proposals between Mid-air and Touch modality.
<img alt="agreement rates" src="https://chloenhy.github.io/assets/images/gesture/agreement-rates.jpg" align="middle"/>

<div style="display: flex; justify-content: center;">
  <img alt="survey" src="https://chloenhy.github.io/assets/images/gesture/gesture-survey.jpg" width="50%" height="50%" align="middle"/>
</div>

##### Qualitative 
<div style="display: flex; justify-content: center;">
    <img alt="example gestures" src="https://chloenhy.github.io/assets/images/gesture/collab-gesture.jpg" width="50%" height="50%" />
    
    <img alt="mid air gestures" src="https://chloenhy.github.io/assets/images/gesture/mid-air-gesture.jpg"/>
    
    <img alt="touch gestures" src="https://chloenhy.github.io/assets/images/gesture/touch-gesture.jpg"/>
</div>

#### Abstract
Interaction techniques for mobile games have developed massively as the capabilities of mobile devices have become sophisticated. However, work on interaction techniques for mobile gaming focuses mainly on single- player games and are expert-designed. This paper attempts to bridge this gap by investigating touch and mid-air gestures as input control for co-located mobile gaming from a user perspective, specifically using board and card games due to the materiality of their game artefacts and the rich interaction between players.
<br>
<br>
Through a gesture elicitation study with 12 dyads, we obtained touch and mid-air gesture proposals for 11 game tasks, as well as insights into user preferences. This paper extends prior gesture elicitation work for cross-device interaction by applying the elicitation methodology in co-located mobile gaming. We contribute to the classification and analysis of 622 gestures, resulting in a consensus gesture set, a gesture taxonomy showing more collaborative gestures in the mid-air modality, and agreement rates showing higher consensus for touch gestures. We identified themes from participants’ feedback, which offer guidelines for future game and gesture design. With the rise of gesture-based control mobile devices, we believe this work can be a reference point for future mobile game gesture design.


The detailed explanation of the agreement rates, taxonomy and gestures are presented in the full paper. Feel free to drop me a message if you are interested in the full paper :)